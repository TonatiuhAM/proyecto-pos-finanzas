# Ejemplo de Resultados - EjecuciÃ³n del 06 Feb 2026

## ðŸ“Š Resumen Ejecutivo

**Fecha**: 06 de Febrero de 2026 00:06:06  
**DuraciÃ³n**: 28 segundos  
**Iteraciones por prueba**: 20  
**Muestras de recursos**: 14 (cada 2 segundos)

---

## ðŸŽ¯ Rendimiento (Latencias)

### Resultados por MÃ³dulo

| Prueba | Latencia Promedio | Estado |
|--------|-------------------|--------|
| Frontend HTML | 0.562 ms | ðŸŸ¢ Excelente |
| Login | 3.154 ms | ðŸŸ¢ Excelente |
| SQL Queries | < 0.01 ms | ðŸŸ¢ Excepcional |
| GET /productos | 13.0 ms | ðŸŸ¡ Bueno |
| GET /producto/{id} | 4.4 ms | ðŸŸ¢ Muy bueno |
| ML Health | 1.0 ms | ðŸŸ¢ Excelente |
| ML Predict | 1.4 ms | ðŸ”´ Revisar |

---

## ðŸ’» Recursos del Sistema

### pos_backend (Spring Boot)

```
CPU:
  â”œâ”€ Promedio: 1.94%
  â”œâ”€ Pico: 9.10%
  â””â”€ Estado: âœ… Normal

RAM:
  â”œâ”€ Promedio: 496.61 MB
  â”œâ”€ Pico: 497.80 MB
  â””â”€ Estado: âš ï¸  Uso alto (6.14% del sistema)

Disco I/O (durante pruebas):
  â”œâ”€ Lectura: 20.48 MB
  â””â”€ Escritura: 0.00 MB

Red I/O (durante pruebas):
  â”œâ”€ Entrada: 0.60 MB
  â””â”€ Salida: 0.60 MB

Top Procesos:
  1. ps aux --sort=- (33.30% CPU - comando de monitoreo)
  2. java -XX:TieredStopAtLevel=1 (0.40% CPU, 2.60% MEM - aplicaciÃ³n Spring Boot)
  3. java maven wrapper (0.10% CPU, 0.50% MEM - proceso Maven)
```

### pos_database (PostgreSQL)

```
CPU:
  â”œâ”€ Promedio: 7.86%
  â”œâ”€ Pico: 24.14%
  â””â”€ Estado: âœ… Normal (picos esperados durante queries)

RAM:
  â”œâ”€ Promedio: 55.85 MB
  â”œâ”€ Pico: 56.36 MB
  â””â”€ Estado: âœ… Excelente (< 1% del sistema)

Disco I/O (durante pruebas):
  â”œâ”€ Lectura: 3.00 MB
  â””â”€ Escritura: 0.00 MB

Red I/O (durante pruebas):
  â”œâ”€ Entrada: 0.30 MB
  â””â”€ Salida: 0.40 MB

Top Procesos:
  1. ps aux --sort=- (50.00% CPU - comando de monitoreo)
  2. postgres: walwriter (0.00% CPU - proceso de escritura de logs)
  3. postgres: idle (0.10% MEM - conexiÃ³n inactiva)
```

### pos_frontend (Nginx)

```
CPU:
  â”œâ”€ Promedio: 0.03%
  â”œâ”€ Pico: 0.19%
  â””â”€ Estado: âœ… Excelente (casi inactivo)

RAM:
  â”œâ”€ Promedio: 8.28 MB
  â”œâ”€ Pico: 9.14 MB
  â””â”€ Estado: âœ… Excelente (< 0.1% del sistema)

Disco I/O (durante pruebas):
  â”œâ”€ Lectura: 5.00 MB
  â””â”€ Escritura: 0.00 MB

Red I/O (durante pruebas):
  â”œâ”€ Entrada: 0.00 MB
  â””â”€ Salida: 0.02 MB

Observaciones:
  - Extremadamente ligero (Nginx solo sirve archivos estÃ¡ticos)
  - Sin escritura a disco (todo en memoria)
  - Red mÃ­nima (solo 20KB salientes)
```

### pos_ml_prediction_api (FastAPI)

```
CPU:
  â”œâ”€ Promedio: 0.18%
  â”œâ”€ Pico: 0.68%
  â””â”€ Estado: âœ… Excelente

RAM:
  â”œâ”€ Promedio: 103.60 MB
  â”œâ”€ Pico: 104.30 MB
  â””â”€ Estado: âš ï¸  Uso medio (1.28% del sistema)

Disco I/O (durante pruebas):
  â”œâ”€ Lectura: 1.00 MB
  â””â”€ Escritura: 1.00 MB

Red I/O (durante pruebas):
  â”œâ”€ Entrada: 0.10 MB
  â””â”€ Salida: 0.01 MB

Observaciones:
  - CPU muy baja (posiblemente no ejecuta modelo real)
  - RAM constante (~104 MB)
  - I/O mÃ­nimo
```

---

## ðŸ” AnÃ¡lisis Detallado

### âœ… Fortalezas

1. **Frontend ultrarrÃ¡pido**
   - Latencia: 0.562 ms
   - Uso de recursos: MÃ­nimo (0.03% CPU, 8 MB RAM)
   - Nginx sirviendo archivos estÃ¡ticos es Ã³ptimo

2. **Base de datos eficiente**
   - Queries SQL < 0.01 ms (cache muy efectivo)
   - Uso de RAM: Solo 56 MB
   - CPU en picos del 24% solo durante queries intensivas

3. **Backend Spring Boot estable**
   - Latencias aceptables (4-13 ms segÃºn endpoint)
   - CPU baja promedio (1.94%)
   - RAM estable en ~497 MB

4. **ML Service responsive**
   - Health checks en ~1 ms
   - CPU y RAM bajos

### âš ï¸  Ãreas de AtenciÃ³n

1. **GET /productos (13 ms)**
   - **Estado**: ðŸŸ¡ Aceptable pero escalarÃ¡ mal
   - **Problema**: Con 19 productos toma 13ms. Con 1000 productos podrÃ­a tomar 680ms
   - **RecomendaciÃ³n**: Implementar paginaciÃ³n (lÃ­mite de 20-50 items por pÃ¡gina)
   - **Impacto**: ReducirÃ­a latencia a < 20 ms incluso con 10,000 productos

2. **ML Predict (1.4 ms)**
   - **Estado**: ðŸ”´ Sospechoso
   - **Problema**: Demasiado rÃ¡pido para una predicciÃ³n real
   - **AnÃ¡lisis**: 
     - Latencia casi idÃ©ntica a health check (1.4ms vs 1.0ms)
     - CPU del ML Service muy bajo (0.18% promedio)
     - Sin picos de CPU durante las 20 predicciones
   - **HipÃ³tesis**: Posiblemente devuelve respuesta mock o cached
   - **PredicciÃ³n real esperada**: 50-500 ms
   - **RecomendaciÃ³n**: Revisar cÃ³digo del endpoint /predict para confirmar que:
     - Carga el modelo correctamente
     - Ejecuta la inferencia
     - Procesa datos de entrada

3. **RAM de Backend con flag "MEM_ALTO"**
   - **Estado**: âš ï¸  Indicador de precauciÃ³n
   - **AnÃ¡lisis**: 
     - El script marca "MEM_ALTO_PROMEDIO" y "MEM_CRITICO_PICO"
     - Sin embargo, solo usa 497 MB de 8096 MB (6.14%)
     - **Este es un FALSO POSITIVO**
   - **Causa**: El threshold estÃ¡ configurado para % dentro del contenedor, no del sistema
   - **AcciÃ³n**: Ignorar este warning. 497 MB para Spring Boot es normal

### ðŸ“ˆ Uso Total del Sistema

```
CPU combinada (todos los contenedores): ~10% (suficiente headroom)
RAM combinada: ~665 MB de 8096 MB (8.2% usado)
Disco leÃ­do: ~29 MB en 28 segundos
Disco escrito: ~1 MB en 28 segundos
Red enviada: ~1 MB
Red recibida: ~1 MB
```

**ConclusiÃ³n**: El sistema tiene mucho margen para crecer. Con solo 8% de RAM usada y 10% de CPU, podrÃ­a manejar 5-10x mÃ¡s carga.

---

## ðŸŽ¯ Prioridades de AcciÃ³n

### Alta Prioridad ðŸ”´

1. **Verificar ML Predict**
   - Revisar archivo: `ml-service/app/main.py` (o similar)
   - Buscar el endpoint POST `/predict`
   - Confirmar que carga modelo y ejecuta inferencia
   - Si es mock, implementar lÃ³gica real
   - Re-ejecutar pruebas y verificar latencia > 50ms

### Media Prioridad ðŸŸ¡

2. **Implementar PaginaciÃ³n en /productos**
   - Modificar: `backend/controller/ProductoController.java`
   - Agregar parÃ¡metros: `?page=0&size=20`
   - Usar `Pageable` de Spring Data
   - Reducir carga para grandes datasets

3. **Agregar Pruebas de Carga**
   - Simular 10, 50, 100 usuarios concurrentes
   - Usar herramienta: Apache JMeter o Gatling
   - Identificar punto de saturaciÃ³n

### Baja Prioridad ðŸŸ¢

4. **Optimizar filtros de Spring Security** (si es necesario)
   - Actualmente agrega ~5-7ms por request
   - Solo optimizar si latencia se vuelve crÃ­tica en producciÃ³n

5. **Monitoreo Continuo**
   - Configurar Spring Boot Actuator + Prometheus
   - Alertas si P95 > threshold
   - Dashboard en Grafana

---

## ðŸ“Š ComparaciÃ³n con Valores Esperados

| MÃ©trica | Valor Obtenido | Esperado (Dev) | ProducciÃ³n | Estado |
|---------|----------------|----------------|------------|--------|
| Frontend | 0.6 ms | < 1 ms | < 50 ms | âœ… |
| Login | 3.2 ms | < 5 ms | < 100 ms | âœ… |
| API simple | 4.4 ms | < 10 ms | < 100 ms | âœ… |
| API lista | 13.0 ms | < 20 ms | < 150 ms | âœ… |
| SQL query | < 0.01 ms | < 1 ms | < 10 ms | âœ… |
| ML Predict | 1.4 ms | 50-200 ms | 100-500 ms | âŒ |

**Nota**: Valores de producciÃ³n incluyen +30-50ms de latencia de red real.

---

## ðŸ’¡ Recomendaciones Generales

### Optimizaciones No Urgentes

El sistema estÃ¡ funcionando bien. No requiere optimizaciones inmediatas excepto:
- âœ… Verificar ML Predict
- âœ… Implementar paginaciÃ³n antes de agregar 100+ productos

### PreparaciÃ³n para ProducciÃ³n

1. **Agregar cachÃ©** (Redis o Caffeine)
   - Para GET /productos (TTL: 5-10 minutos)
   - Para categorÃ­as y proveedores
   - ReducirÃ¡ latencia de 13ms â†’ 2-3ms

2. **Connection pooling**
   - HikariCP ya estÃ¡ incluido en Spring Boot
   - Verificar configuraciÃ³n Ã³ptima (pool size ~10-20)

3. **Ãndices de BD**
   - Revisar con EXPLAIN ANALYZE queries lentas
   - Agregar Ã­ndices compuestos si es necesario

4. **Escalado horizontal**
   - Con el bajo uso actual (8% RAM, 10% CPU)
   - Una sola instancia puede manejar 500-1000 usuarios simultÃ¡neos
   - Considerar escalado solo si se superan 1000 usuarios

---

## ðŸ“ Archivos de Esta EjecuciÃ³n

```
resultados/
â”œâ”€â”€ 01-10_*.csv                      # Latencias individuales (10 archivos)
â”œâ”€â”€ recursos_raw_20260206_000606.csv # Recursos capturados (14 muestras)
â”œâ”€â”€ procesos_raw_20260206_000606.csv # Top procesos
â”œâ”€â”€ RESUMEN_LATENCIAS_*.csv          # Consolidado de latencias
â”œâ”€â”€ RESUMEN_RECURSOS_*.csv           # Consolidado de recursos
â”œâ”€â”€ TOP_PROCESOS_*.csv               # AnÃ¡lisis de procesos
â””â”€â”€ REPORTE_RECURSOS_*.txt           # Reporte completo
```

---

**Fin del documento**
