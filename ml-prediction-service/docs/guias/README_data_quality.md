# üìä Analizador de Calidad de Datos - Sistema POS

## Descripci√≥n

Script completo desarrollado por un **Ingeniero de Datos Senior** para an√°lisis exhaustivo de calidad de datos en DataFrames post-feature engineering del sistema POS. Dise√±ado espec√≠ficamente para validar la calidad de datos antes del entrenamiento de modelos XGBoost de predicci√≥n de compras.

## üéØ Caracter√≠sticas Principales

### ‚úÖ An√°lisis de Completitud
- Detecci√≥n de valores faltantes por columna
- C√°lculo de porcentajes de completitud
- Identificaci√≥n de patrones de datos faltantes
- Alertas para columnas con alta tasa de valores faltantes (>5%)

### üî¢ An√°lisis de Tipos de Datos
- Clasificaci√≥n autom√°tica de caracter√≠sticas (num√©ricas, categ√≥ricas, temporales)
- Detecci√≥n de inconsistencias de tipado
- Identificaci√≥n de columnas num√©ricas que podr√≠an ser categ√≥ricas
- Verificaci√≥n de columnas categ√≥ricas que podr√≠an ser num√©ricas

### üéØ Detecci√≥n de Outliers
- M√©todos disponibles: IQR, Z-Score, Isolation Forest
- Estad√≠sticas detalladas por columna
- Identificaci√≥n de valores extremos con sus √≠ndices
- C√°lculo de porcentajes de outliers por caracter√≠stica

### üìà An√°lisis de Distribuciones
- Estad√≠sticas descriptivas completas
- Tests de normalidad (Shapiro-Wilk)
- C√°lculo de asimetr√≠a y curtosis
- Clasificaci√≥n autom√°tica del tipo de distribuci√≥n
- An√°lisis de coeficientes de variaci√≥n

### üîó An√°lisis de Correlaciones
- Matriz de correlaci√≥n completa para variables num√©ricas
- Detecci√≥n de correlaciones altas (umbral configurable)
- Identificaci√≥n de problemas de multicolinealidad (>0.95)
- Correlaciones espec√≠ficas con variables objetivo
- Top correlaciones positivas y negativas

### ‚è∞ Detecci√≥n de Data Drift
- An√°lisis temporal de cambios en distribuciones
- Comparaci√≥n entre m√∫ltiples per√≠odos temporales
- M√©tricas de drift: coeficiente de variaci√≥n, cambio relativo
- Detecci√≥n autom√°tica de caracter√≠sticas con drift significativo
- Visualizaci√≥n de tendencias temporales

### üìã Reportes Integrales
- Reporte JSON completo con todos los an√°lisis
- Reporte HTML interactivo con visualizaciones
- Puntuaci√≥n de calidad de datos (0-100)
- Resumen ejecutivo con flags de calidad
- Recomendaciones automatizadas basadas en hallazgos

## üõ†Ô∏è Instalaci√≥n y Dependencias

```bash
# Instalar dependencias requeridas
pip install pandas numpy matplotlib seaborn scipy plotly
```

### Dependencias Principales:
- `pandas`: Manipulaci√≥n de DataFrames
- `numpy`: Operaciones num√©ricas
- `matplotlib`: Visualizaciones b√°sicas
- `seaborn`: Visualizaciones estad√≠sticas
- `scipy`: Tests estad√≠sticos
- `plotly`: Visualizaciones interactivas para HTML

## üìö Uso B√°sico

### 1. An√°lisis R√°pido con Datos Propios

```python
from data_quality_analyzer import DataQualityAnalyzer
import pandas as pd

# Cargar tu DataFrame post-feature engineering
df = pd.read_csv('tu_dataset_procesado.csv')

# Crear analizador
analyzer = DataQualityAnalyzer(
    df=df,
    target_columns=['cantidad_a_comprar', 'prioridad_compra']  # Opcional
)

# Generar reporte completo
report = analyzer.generate_full_report(
    output_file='reporte_calidad.json'
)

# Mostrar puntuaci√≥n de calidad
print(f"Puntuaci√≥n de Calidad: {report['executive_summary']['data_quality_score']}/100")
```

### 2. An√°lisis Componente por Componente

```python
# An√°lisis individual de cada componente
completeness = analyzer.analyze_completeness()
outliers = analyzer.analyze_outliers(method='iqr')
correlations = analyzer.analyze_correlations(threshold=0.8)
distributions = analyzer.analyze_distributions()
drift = analyzer.detect_data_drift()

print(f"Completitud general: {completeness['overall_completeness_pct']}%")
print(f"Outliers detectados: {outliers['summary']['total_outliers_detected']}")
print(f"Correlaciones altas: {correlations['summary']['high_correlation_pairs']}")
```

### 3. Generaci√≥n de Datos de Prueba

```python
# Generar datos de prueba realistas basados en el sistema POS
df_test = DataQualityAnalyzer.generate_test_data(
    n_samples=2000,      # N√∫mero de registros
    n_features=30,       # N√∫mero de caracter√≠sticas
    include_issues=True  # Incluir problemas de calidad
)

print(f"Datos generados: {df_test.shape}")
print(f"Columnas: {list(df_test.columns)}")
```

### 4. Generaci√≥n de Reporte HTML

```python
from data_quality_html_report import HTMLReportGenerator

# Generar reporte HTML interactivo
html_generator = HTMLReportGenerator(report)
html_content = html_generator.generate_html_report('reporte_calidad.html')

print("Reporte HTML generado exitosamente!")
```

## üéÆ Demo Completo

```bash
# Ejecutar demo completo con datos de prueba
python data_quality_analyzer.py
```

Este comando ejecutar√°:
1. Generaci√≥n de datos de prueba (2000 muestras, 25 caracter√≠sticas)
2. An√°lisis completo de calidad
3. Generaci√≥n de reporte JSON
4. Generaci√≥n de reporte HTML
5. Visualizaci√≥n de resumen ejecutivo en consola

## üìä Interpretaci√≥n de Resultados

### Puntuaci√≥n de Calidad (0-100)
- **80-100**: Excelente calidad, datos listos para ML
- **60-79**: Buena calidad, algunas mejoras menores
- **40-59**: Calidad regular, requiere atenci√≥n
- **<40**: Problemas serios, requiere limpieza antes de usar

### Flags de Calidad
- `high_missing_data`: >5% de datos faltantes
- `excessive_outliers`: >5% de outliers en el dataset
- `multicollinearity_issues`: Correlaciones >0.95
- `data_drift_detected`: Cambios temporales significativos

### Umbrales de Alerta
- **Completitud**: <95% requiere atenci√≥n
- **Outliers**: >5% del dataset indica problemas
- **Correlaciones**: >0.8 alta, >0.95 multicolinealidad
- **Drift**: Coef. variaci√≥n >0.1 o cambio >20%

## üß™ Caracter√≠sticas de los Datos de Prueba

Los datos de prueba simulan el sistema POS real con:

### Caracter√≠sticas del Producto
- `precio_producto`: Precios con distribuci√≥n log-normal
- `stock_actual`: Inventario actual (Poisson)
- `rotacion_inventario`: Rotaci√≥n de productos

### Caracter√≠sticas Temporales
- `ventas_ultimos_7_dias`: Ventas recientes
- `tendencia_ventas`: Tendencia hist√≥rica
- `estacionalidad_mes`: Patrones estacionales

### Caracter√≠sticas de Proveedor
- `confiabilidad_proveedor`: Rating de proveedores
- `tiempo_entrega_promedio`: Tiempos de entrega

### Variables Objetivo
- `cantidad_a_comprar`: Cantidad predicha (entero positivo)
- `prioridad_compra`: Prioridad 1-5 (categ√≥rica ordinal)

## üîß Personalizaci√≥n y Extensi√≥n

### A√±adir Nuevos M√©todos de Detecci√≥n de Outliers

```python
def analyze_outliers_custom(self, method='isolation_forest'):
    if method == 'isolation_forest':
        from sklearn.ensemble import IsolationForest
        # Implementar l√≥gica personalizada
    # ... resto de la implementaci√≥n
```

### Personalizar Umbrales

```python
# Personalizar umbrales en el constructor
analyzer = DataQualityAnalyzer(df, target_columns=['target'])

# Modificar umbrales despu√©s de la inicializaci√≥n
outliers = analyzer.analyze_outliers()  # IQR por defecto
correlations = analyzer.analyze_correlations(threshold=0.7)  # Umbral personalizado
```

### A√±adir Nuevas M√©tricas

```python
def analyze_feature_importance(self) -> Dict[str, Any]:
    """A√±adir an√°lisis de importancia de caracter√≠sticas."""
    # Tu implementaci√≥n personalizada
    pass
```

## üìà Casos de Uso Espec√≠ficos

### 1. Validaci√≥n Pre-Entrenamiento
```python
# Antes de entrenar modelo XGBoost
analyzer = DataQualityAnalyzer(df_features)
report = analyzer.generate_full_report()

if report['executive_summary']['data_quality_score'] < 70:
    print("‚ö†Ô∏è Calidad insuficiente para entrenamiento")
    # Implementar limpieza de datos
else:
    print("‚úÖ Datos listos para entrenamiento")
```

### 2. Monitoreo en Producci√≥n
```python
# Comparar calidad entre datasets
analyzer_train = DataQualityAnalyzer(df_train)
analyzer_prod = DataQualityAnalyzer(df_production)

# Detectar drift entre entrenamiento y producci√≥n
drift_analysis = analyzer_prod.detect_data_drift()
if drift_analysis['summary']['features_with_drift'] > 0:
    print("üö® Drift detectado - considerar reentrenamiento")
```

### 3. Auditor√≠a de Calidad Peri√≥dica
```python
# Script para ejecutar semanalmente
def weekly_quality_audit(data_path):
    df = pd.read_csv(data_path)
    analyzer = DataQualityAnalyzer(df)
    
    report = analyzer.generate_full_report(
        output_file=f'audit_{datetime.now().strftime("%Y%m%d")}.json'
    )
    
    # Enviar alerta si calidad < umbral
    if report['executive_summary']['data_quality_score'] < 80:
        send_quality_alert(report)
```

## üöÄ Mejores Pr√°cticas

### 1. Frecuencia de An√°lisis
- **Pre-entrenamiento**: Siempre antes de entrenar modelos
- **Producci√≥n**: Semanal o cuando lleguen nuevos datos
- **Post-cambios**: Despu√©s de modificar pipeline de datos

### 2. Automatizaci√≥n
```python
# Integrar en pipeline de MLOps
def validate_data_quality(df, min_score=75):
    analyzer = DataQualityAnalyzer(df)
    report = analyzer.generate_full_report()
    
    score = report['executive_summary']['data_quality_score']
    if score < min_score:
        raise ValueError(f"Calidad insuficiente: {score}<{min_score}")
    
    return report
```

### 3. Almacenamiento de Reportes
```python
# Guardar reportes con timestamp para seguimiento hist√≥rico
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_file = f'reports/quality_report_{timestamp}.json'
report = analyzer.generate_full_report(output_file)
```

## üîç Troubleshooting

### Error: "No se encontr√≥ columna temporal"
```python
# Especificar columna temporal manualmente
drift = analyzer.detect_data_drift(temporal_column='fecha_venta')
```

### Error: "Datos insuficientes"
```python
# Verificar tama√±o m√≠nimo del dataset
if len(df) < 100:
    print("Dataset muy peque√±o para an√°lisis completo")
```

### Warning: "Muchos valores faltantes"
```python
# Filtrar columnas con pocos valores antes del an√°lisis
df_clean = df.dropna(thresh=len(df)*0.7, axis=1)  # Mantener columnas con <30% faltantes
```

## üìû Soporte y Contribuciones

Este script est√° dise√±ado para el sistema POS espec√≠fico pero es f√°cilmente adaptable a otros proyectos de ML. Para casos de uso espec√≠ficos o extensiones, consultar con el equipo de datos.

### Estructura de Archivos Generados:
```
ml-prediction-service/
‚îú‚îÄ‚îÄ data_quality_analyzer.py          # Script principal
‚îú‚îÄ‚îÄ data_quality_html_report.py       # Generador de HTML
‚îú‚îÄ‚îÄ data_quality_report.json          # Reporte JSON detallado
‚îú‚îÄ‚îÄ data_quality_report.html          # Reporte HTML interactivo
‚îî‚îÄ‚îÄ README_data_quality.md            # Esta documentaci√≥n
```

---

**Desarrollado por**: Ingeniero de Datos Senior  
**Versi√≥n**: 1.0.0  
**Fecha**: 14 de octubre de 2025  
**Sistema**: POS & Gesti√≥n Integral - Motor de Predicciones ML