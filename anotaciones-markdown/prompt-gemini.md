# Prompt para Gemini: AnÃ¡lisis del Sistema de PredicciÃ³n de Inventario con XGBoost y Factores de Escala

## ğŸ“‹ Contexto del Sistema

Soy dueÃ±o de un restaurante de tacos en MÃ©xico y he implementado un sistema de predicciÃ³n de inventario basado en Machine Learning para optimizar mis compras diarias. Sin embargo, existe una **discrepancia significativa** entre las ventas registradas en mi sistema POS y las compras reales que hago, debido a que no todas las ventas se registran (alta afluencia de clientes, operaciÃ³n rÃ¡pida).

---

## ğŸ¤– Â¿QuÃ© es XGBoost y cÃ³mo lo usamos?

### DefiniciÃ³n
**XGBoost (eXtreme Gradient Boosting)** es un algoritmo de Machine Learning basado en Ã¡rboles de decisiÃ³n que utiliza una tÃ©cnica llamada "gradient boosting". 

### CaracterÃ­sticas principales:
- **Ensemble Learning:** Combina mÃºltiples Ã¡rboles de decisiÃ³n dÃ©biles para crear un modelo fuerte
- **Boosting secuencial:** Cada Ã¡rbol nuevo aprende de los errores de los Ã¡rboles anteriores
- **RegularizaciÃ³n:** Previene el sobreajuste (overfitting) con parÃ¡metros como `max_depth`, `min_child_weight`
- **Manejo de valores faltantes:** Puede trabajar con datos incompletos

### Nuestro uso especÃ­fico:
Entrenamos **DOS modelos XGBoost separados:**

1. **Modelo de Cantidad (`modelo_cantidad`):**
   - **Objetivo:** Predecir cuÃ¡ntas unidades se venderÃ¡n de cada producto
   - **Variable objetivo:** `cantidad_pz` (cantidad en piezas)
   - **Salida:** NÃºmero continuo (ej: 5.3 tacos, que redondeamos a 10 por mÃºltiplo de 10)

2. **Modelo de Prioridad (`modelo_prioridad`):**
   - **Objetivo:** Predecir la urgencia/importancia de compra de cada producto
   - **Variable objetivo:** `prioridad` (0=baja, 1=media, 2=alta)
   - **Salida:** ClasificaciÃ³n de prioridad para la gestiÃ³n de compras

### ParÃ¡metros de configuraciÃ³n usados:
```python
params_cantidad = {
    'objective': 'reg:squarederror',  # RegresiÃ³n (nÃºmeros continuos)
    'max_depth': 6,                   # Profundidad mÃ¡xima de cada Ã¡rbol
    'learning_rate': 0.1,             # Tasa de aprendizaje (quÃ© tan rÃ¡pido aprende)
    'n_estimators': 100,              # NÃºmero de Ã¡rboles
    'min_child_weight': 1,            # Peso mÃ­nimo en cada hoja
    'subsample': 0.8,                 # 80% de datos por Ã¡rbol (evita overfitting)
    'colsample_bytree': 0.8,          # 80% de features por Ã¡rbol
    'random_state': 42                # Semilla para reproducibilidad
}
```

---

## ğŸ“Š Datos de Entrada al Modelo

### 1. Datos HistÃ³ricos de la Base de Datos

Extraemos datos de ventas histÃ³ricas del perÃ­odo: **29 de septiembre al 3 de octubre de 2025** (5 dÃ­as: Lunes a Viernes, periodo de alta actividad).

**Consulta SQL ejecutada:**
```sql
SELECT 
    o.id AS orden_id,
    o.fecha_orden,
    EXTRACT(DOW FROM o.fecha_orden) AS dia_semana,
    EXTRACT(HOUR FROM o.fecha_orden) AS hora,
    dv.productos_id,
    p.nombre AS producto_nombre,
    dv.cantidad AS cantidad_pz,
    dv.precio_unitario,
    dv.subtotal,
    o.total,
    o.descuento,
    o.metodo_pago,
    o.estado
FROM ordenes_de_ventas o
JOIN detalle_ventas dv ON o.id = dv.orden_venta_id
JOIN productos p ON dv.productos_id = p.id
WHERE o.fecha_orden >= '2025-09-29' 
  AND o.fecha_orden <= '2025-10-03'
  AND o.estado != 'cancelada'
ORDER BY o.fecha_orden;
```

**Datos extraÃ­dos:**
- **Total de registros:** 827 Ã³rdenes
- **Muestras entrenamiento:** 567 (70%)
- **Muestras prueba:** 142 (30%)
- **Features generados:** 33 caracterÃ­sticas

**Features (variables) creadas para el modelo:**
- `dia_semana`: 0=Domingo, 1=Lunes, 2=Martes, ..., 6=SÃ¡bado
- `hora`: Hora del dÃ­a (0-23)
- `es_fin_de_semana`: 1 si es sÃ¡bado/domingo, 0 si no
- `es_hora_pico`: 1 si estÃ¡ entre 12-15h o 19-22h, 0 si no
- `productos_id`: ID del producto
- `precio_unitario`: Precio por unidad
- `total_orden`: Total de la orden
- Variables codificadas por producto (one-hot encoding)
- Promedios mÃ³viles y tendencias temporales

### 2. Compras Reales del Restaurante

Este es el archivo JSON que tÃº me proporcionaste con las **compras reales** que haces cada dÃ­a:

```json
[
  {
    "Producto": "Pollo (tacos)",
    "Lunes": 200,
    "Martes": 160,
    "MiÃ©rcoles": 160,
    "Jueves": 200,
    "Viernes": 200,
    "SÃ¡bado": 160
  },
  {
    "Producto": "Bistec (tacos)",
    "Lunes": 300,
    "Martes": 240,
    "MiÃ©rcoles": 240,
    "Jueves": 300,
    "Viernes": 300,
    "SÃ¡bado": 200
  },
  {
    "Producto": "Longaniza (tacos)",
    "Lunes": 200,
    "Martes": 200,
    "MiÃ©rcoles": 200,
    "Jueves": 200,
    "Viernes": 300,
    "SÃ¡bado": 200
  },
  {
    "Producto": "Chuleta (tacos)",
    "Lunes": 60,
    "Martes": 60,
    "MiÃ©rcoles": 60,
    "Jueves": 60,
    "Viernes": 60,
    "SÃ¡bado": 60
  },
  {
    "Producto": "Arrachera (tacos)",
    "Lunes": 200,
    "Martes": 140,
    "MiÃ©rcoles": 160,
    "Jueves": 200,
    "Viernes": 240,
    "SÃ¡bado": 160
  },
  {
    "Producto": "Costilla (tacos)",
    "Lunes": 120,
    "Martes": 100,
    "MiÃ©rcoles": 100,
    "Jueves": 120,
    "Viernes": 160,
    "SÃ¡bado": 100
  },
  {
    "Producto": "Coca (piezas)",
    "Lunes": 92,
    "Martes": 66,
    "MiÃ©rcoles": 66,
    "Jueves": 92,
    "Viernes": 100,
    "SÃ¡bado": 66
  },
  {
    "Producto": "Mundet (piezas)",
    "Lunes": 66,
    "Martes": 48,
    "MiÃ©rcoles": 48,
    "Jueves": 66,
    "Viernes": 70,
    "SÃ¡bado": 48
  }
]
```

**InterpretaciÃ³n:**
- Estas cantidades representan **unidades listas para vender** (tacos ya preparados o bebidas)
- Las compras son **diarias** (cada dÃ­a compras para ese dÃ­a especÃ­fico)
- Unidades ya convertidas: 1 kg de carne = 20 tacos
- **Total comprado semanalmente:** 6,948 unidades

---

## ğŸ”¢ Sistema de Factores de Escala

### El Problema Identificado

**Discrepancia entre predicciones base y realidad:**
- **Ventas registradas en BD:** ~1,087 unidades/semana
- **Compras reales:** ~6,948 unidades/semana
- **Factor de discrepancia:** ~6.4Ã— subestimaciÃ³n

**Causa raÃ­z:** No todas las ventas se registran en el sistema POS debido a:
- Alta afluencia de clientes en horas pico
- OperaciÃ³n rÃ¡pida sin tiempo para registrar cada venta
- Ventas para llevar que se anotan manualmente

### La SoluciÃ³n: Factores de Escala

Implementamos un **sistema hÃ­brido de factores de escala** que ajusta las predicciones del modelo base multiplicÃ¡ndolas por factores calculados histÃ³ricamente.

### MÃ©todo de Granularidad HÃ­brida

**LÃ³gica de aplicaciÃ³n (en orden de preferencia):**

1. **Factor Producto + DÃ­a** (mÃ¡s especÃ­fico):
   - Si hay â‰¥3 observaciones histÃ³ricas para ese producto en ese dÃ­a especÃ­fico
   - Ejemplo: Factor para "Pollo los Lunes" = 2.63Ã—
   
2. **Factor Producto** (fallback medio):
   - Si no hay suficientes datos para producto+dÃ­a
   - Usa el promedio de todos los dÃ­as de ese producto
   - Ejemplo: Factor promedio para "Pollo" = 5.88Ã—

3. **Factor Global** (fallback final):
   - Si no hay datos suficientes del producto
   - Usa el promedio de todos los productos
   - Factor global = 5.61Ã—

### FÃ³rmula de CÃ¡lculo del Factor

Para cada combinaciÃ³n producto-dÃ­a:

```
Factor_Escala = Compras_Reales / Ventas_Registradas
```

**Ejemplo: Pollo los Lunes**
- Ventas registradas: 76 tacos (de 34 Ã³rdenes)
- Compras reales: 200 tacos
- **Factor calculado: 200 / 76 = 2.63Ã—**

**InterpretaciÃ³n:** Por cada taco de pollo registrado los lunes, en realidad se venden 2.63 tacos.

### PredicciÃ³n Final

```
PredicciÃ³n_Final = ((PredicciÃ³n_Base_XGBoost Ã— Factor_Escala) Ã— Margen_Seguridad) 
                   redondeada a mÃºltiplos de 10
```

Donde:
- `PredicciÃ³n_Base_XGBoost`: Salida directa del modelo entrenado
- `Factor_Escala`: Factor hÃ­brido seleccionado (producto+dÃ­a, producto, o global)
- `Margen_Seguridad`: 1.15 (15% adicional para evitar desabasto)
- Redondeo a mÃºltiplos de 10 para facilitar compras

---

## ğŸ“ˆ Factores de Escala Calculados

AquÃ­ estÃ¡n los factores reales calculados por el sistema (archivo JSON que te adjunto):

### Resumen por Producto

| Producto | Factor Promedio | Rango de Factores | InterpretaciÃ³n |
|----------|----------------|-------------------|----------------|
| **Pollo** | 5.88Ã— | 2.63Ã— - 8.89Ã— | Relativamente estable, buena cobertura |
| **Bistec** | 3.87Ã— | 3.19Ã— - 4.00Ã— | **Muy estable** (mejor caso) |
| **Longaniza** | 66.67Ã— | 28.57Ã— - 66.67Ã— | âš ï¸ **EXTREMO** - pocas ventas registradas |
| **Chuleta** | 7.50Ã— | 5.00Ã— - 15.00Ã— | Moderadamente variable |
| **Arrachera** | 10.91Ã— | 6.25Ã— - 16.67Ã— | Alta variabilidad semanal |
| **Costilla** | 4.62Ã— | 3.70Ã— - 26.67Ã— | Estable excepto viernes (26.67Ã—) |
| **Coca** | 2.00Ã— | 1.10Ã— - 4.76Ã— | Mejor registro (bebidas mÃ¡s fÃ¡ciles) |
| **Mundet** | 5.33Ã— | 3.68Ã— - 6.60Ã— | Estable |

### EstadÃ­sticas Globales

- **Media:** 13.24Ã—
- **Mediana:** 5.88Ã—
- **DesviaciÃ³n estÃ¡ndar:** 19.00 (alta variabilidad)
- **Rango:** 1.10Ã— - 66.67Ã—
- **Total de factores calculados:** 48 (8 productos Ã— 6 dÃ­as)

### Advertencias del Sistema

El sistema detectÃ³ **3 factores extremos** para Longaniza:

1. **Martes:** 66.67Ã— (ventas registradas: 3, compras: 200)
2. **MiÃ©rcoles:** 100.00Ã— (ventas registradas: 2, compras: 200)
3. **Jueves:** 200.00Ã— (ventas registradas: 1, compra: 200)

**Posibles causas:**
- Producto nuevo con pocas ventas histÃ³ricas
- Casi ninguna venta se registra en el sistema
- Alta merma o desperdicio
- Error en los datos de compras

---

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

### ComparaciÃ³n: SIN Escala vs CON Escala

| MÃ©trica | BASE (sin escala) | ESCALADA (con factores) | Mejora |
|---------|-------------------|--------------------------|--------|
| **MAE** (Error Absoluto Medio) | 122.10 unidades | 46.25 unidades | **+62.1%** |
| **MAPE** (Error Porcentual Medio) | 83.14% | 32.90% | **+60.4%** |
| **RÂ² Score** | -2.20 | 0.12 | Mejora significativa |
| **RMSE** | ~145 | 71.86 | +50.4% |
| **Total Predicho** | 1,087 unidades | 6,840 unidades | 529.3% ajuste |
| **PrecisiÃ³n Total** | 15.6% del real | 98.4% del real | **Excelente** |

### InterpretaciÃ³n de MÃ©tricas

**MAE (Mean Absolute Error - Error Absoluto Medio):**
- Promedio de la diferencia absoluta entre predicciÃ³n y realidad
- **46.25 unidades** significa que en promedio nos equivocamos por ~46 unidades por producto-dÃ­a
- MÃ©trica en las mismas unidades que los datos (fÃ¡cil de interpretar)

**MAPE (Mean Absolute Percentage Error - Error Porcentual Absoluto Medio):**
- Promedio del error porcentual
- **32.90%** significa que en promedio nos equivocamos por ~33%
- Ãštil para comparar productos de diferentes escalas

**RÂ² Score (Coeficiente de DeterminaciÃ³n):**
- Mide quÃ© tan bien el modelo explica la variabilidad de los datos
- Rango: -âˆ a 1.0 (1.0 = perfecto)
- **0.12** indica que el modelo explica el 12% de la variabilidad
- Bajo pero aceptable dado el contexto (ventas con alta aleatoriedad)

**RMSE (Root Mean Squared Error):**
- Similar a MAE pero penaliza mÃ¡s los errores grandes
- **71.86** indica que los errores grandes siguen presentes pero controlados

---

## ğŸ¯ Productos con Mejor/Peor DesempeÃ±o

### TOP 3 Mejores Predicciones (Error < 30%)

1. **Pollo (tacos):** 28.3% error - Factor 5.88Ã— funciona bien
2. **Bistec (tacos):** 28.9% error - Factor mÃ¡s estable (3.87Ã—)
3. **Arrachera (tacos):** 28.9% error - A pesar de alta variabilidad

### TOP 3 Productos a Mejorar (Error > 31%)

1. **Longaniza (tacos):** 49.2% error - Factor extremo (66.67Ã—) por pocas ventas registradas
2. **Mundet (piezas):** 34.5% error - Bebida de menor consumo
3. **Coca (piezas):** 31.9% error - Aunque tiene mejor registro

---

## ğŸ¨ Visualizaciones Generadas

El sistema genera 5 grÃ¡ficos en formato PNG:

1. **prediccion_vs_real_productos.png:** GrÃ¡fico de barras comparando predicciÃ³n escalada vs compras reales por producto (total semanal)

2. **tendencias_por_dia.png:** GrÃ¡ficos de lÃ­neas mostrando tendencias para cada dÃ­a de la semana (Lunes a SÃ¡bado)

3. **heatmap_errores.png:** Mapa de calor mostrando el error porcentual por producto y dÃ­a (identifica patrones)

4. **distribucion_errores.png:** Histograma de la distribuciÃ³n de errores (verifica si son normales)

5. **mae_por_dia.png:** GrÃ¡fico de barras del MAE promedio por dÃ­a de la semana (identifica dÃ­as problemÃ¡ticos)

---

## â“ Preguntas para Gemini

Te adjunto:
1. **El archivo HTML completo del reporte** (`reporte_completo.html`)
2. **El archivo JSON con los factores de escala** (`factores_escala_calculados.json`)

Por favor, ayÃºdame a entender:

### 1. InterpretaciÃ³n de los Factores de Escala
- Â¿Por quÃ© ciertos productos tienen factores tan diferentes?
- Â¿Es normal que Longaniza tenga un factor de 66.67Ã—?
- Â¿Los factores sugieren algÃºn patrÃ³n de comportamiento de mis clientes o de mi operaciÃ³n?
- Â¿Hay correlaciÃ³n entre el tipo de producto (carnes vs bebidas) y sus factores?

### 2. Impacto en los Resultados
- Con un MAPE de 32.90%, Â¿es este sistema confiable para planificar compras?
- Â¿Los factores extremos (Longaniza, Viernes Costilla) estÃ¡n afectando negativamente la mÃ©trica global?
- Â¿DeberÃ­a eliminar productos con factores extremos del sistema automatizado?
- Â¿QuÃ© significa que el modelo base tenga RÂ²=-2.20 pero con escala sea 0.12?

### 3. AnÃ¡lisis de Patrones
- Â¿QuÃ© dÃ­as de la semana son mÃ¡s difÃ­ciles de predecir y por quÃ©?
- Â¿Hay productos que claramente necesitan un sistema de registro mejorado?
- Â¿Los factores de escala revelan problemas operacionales especÃ­ficos?

### 4. RepresentaciÃ³n de Resultados
- Â¿CÃ³mo puedo presentar estos resultados a mi equipo de forma clara?
- Â¿QuÃ© grÃ¡ficos adicionales me recomiendas crear?
- Â¿DeberÃ­a crear dashboards diferentes para productos estables vs problemÃ¡ticos?
- Â¿QuÃ© KPIs deberÃ­a monitorear semanalmente?

### 5. Mejoras al Sistema
- Â¿QuÃ© estrategias recomiendas para mejorar el registro de ventas?
- Â¿DeberÃ­a ajustar los umbrales del sistema (ej: umbral_datos_minimos=3)?
- Â¿Hay features adicionales que deberÃ­a agregar al modelo XGBoost?
- Â¿DeberÃ­a entrenar modelos separados por producto en vez de uno general?

### 6. Decisiones de Negocio
- Â¿Puedo confiar en este sistema para automatizar compras?
- Â¿QuÃ© productos deberÃ­a seguir comprando manualmente?
- Â¿El margen de seguridad del 15% es apropiado o deberÃ­a ajustarlo por producto?
- Â¿CÃ³mo manejo la alta variabilidad de productos como Arrachera y Costilla?

---

## ğŸ”§ ConfiguraciÃ³n TÃ©cnica del Sistema

**ParÃ¡metros clave que puedo ajustar:**

```json
{
  "escala_params": {
    "aplicar_escala": true,
    "metodo_granularidad": "hibrido",  // Opciones: "producto_dia", "producto", "global", "hibrido"
    "umbral_datos_minimos": 3,         // MÃ­nimo de observaciones para usar factor producto+dÃ­a
    "factor_minimo": 0.5,              // Alerta si factor < 0.5
    "factor_maximo": 50.0,             // Alerta si factor > 50.0
    "guardar_factores_calculados": true
  },
  "redondeo": {
    "multiplo": 10,                    // Redondear a mÃºltiplos de 10
    "aplicar": true
  },
  "margen_seguridad": 1.15              // 15% adicional
}
```

---

## ğŸ“ Notas Adicionales

- El sistema estÃ¡ implementado en **Python 3.11** con bibliotecas: XGBoost, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn
- La base de datos es **PostgreSQL 14**
- El perÃ­odo de entrenamiento es de **solo 5 dÃ­as** (29 sep - 3 oct 2025), lo cual es **limitado**
- Los datos histÃ³ricos tienen **827 registros de ventas** para entrenar
- El sistema genera reportes automÃ¡ticamente cada vez que se ejecuta

---

## ğŸ¯ Objetivo Final

Quiero entender profundamente:
1. **Â¿Por quÃ© el sistema tomÃ³ estas decisiones de factores?**
2. **Â¿CÃ³mo afectan estos factores a mis resultados operacionales?**
3. **Â¿CÃ³mo puedo representar y comunicar estos resultados efectivamente?**
4. **Â¿QuÃ© acciones concretas debo tomar para mejorar el sistema?**

Gracias por tu anÃ¡lisis detallado.
